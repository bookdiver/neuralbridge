# SDE parameters
sde:
  name: cell
  X_dim: 2
  W_dim: 2
  T: 4.0
  dt: 1.0e-2
  t_scheme: linear
  params_X_unc:
    alpha: 0.0625 
    sigma: 0.1
  params_X_aux:
    alpha: 0.0625
    sigma: 0.1
  u: ["0.1", "-0.1"]
  v: ["2.0", "-0.1"]

# network parameters
network:
  mlp_type: mlp
  out_dim: 2
  hidden_dims: [32, 32, 32, 32]
  t_emb_dim: 32
  t_emb_max_period: 100.0
  t_emb_scaling: 100.0
  activation: tanh
  normalization_type: null
  dropout_rate: 0.0
# network:
#   mlp_type: mlp_large
#   out_dim: 2
#   encoder_dims: [16]
#   decoder_dims: [128, 128]
#   t_emb_dim: 32
#   t_emb_max_period: 10000.0
#   t_emb_scaling: 100.0
#   activation: leaky_relu
#   dropout_rate: 0.0
#   normalization_type: null

# Training parameters
training:
  save_name: cell_normal
  learning_rate: 5.0e-4
  batch_size: 32
  n_iters_per_epoch: 1000
  n_epochs: 20
  ema_decay: 0.995
  optimizer: adam
  warmup_steps_ratio: 0.1
  clip_norm: 1.0
# training:
#   save_name: "cell_normal_reproduced"
#   learning_rate: 0.01
#   batch_size: 50
#   n_iters_per_epoch: 10
#   n_epochs: 100
#   ema_decay: 0.99
#   warmup_steps_ratio: 0.0
#   optimizer: adam
#   clip_norm: null